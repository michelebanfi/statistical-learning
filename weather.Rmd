---
title: "Weather Forecasting"
author: "Michele Banfi 869294"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, comment = NA)
library(knitr)
```
# Project
The aim of the project is to predict whether or not, tomorrow will rain. Given some predictors, such as: `Temperature`, `Dew point`, ... the models will classify the following day as "rainy" or not.


## Libraries
Install packages
```{r message = FALSE}
# install.packages("tidymodels")
# install.packages("tidyverse")
# install.packages("xgboost")
# install.packages("ggplot2")
# install.packages("lubridate")
# install.packages("ranger")
# install.packages("vip")
# install.packages("DiagrammeR")
# install.packages("GGally")
```
Import the libraries used in the project
```{r message = FALSE, warning = FALSE}
library(tidyverse)
library(tidymodels)
library(ggplot2)
library(lubridate)
library(ranger)
library(vip)
library(xgboost)
library(DiagrammeR)
library(GGally)
library(rmarkdown)
```

## Dataset

The dataset used in this project is composed of hourly observation of weather related features. Available <https://huggingface.co/datasets/sayanroy058/Weather-Time-Series-Forecasting>

```{r message=FALSE}
data <- read_csv("dataset.csv")
```
A first visualization of the data
```{r}
paged_table(head(data))
```
Check for missing values in the dataset
```{r}
sum(is.na(data))
```
From a first sight the column `snowfall` seems empty (all equal to 0), so if that's the case the column will be removed; this imply that precipitation and rain are the same, so precipitation will be removed.
```{r}
# Check if the 'snow' column is all zeros and remove it if true
if (all(data$`snowfall (cm)` == 0)) {
  data <- data %>% select(-`snowfall (cm)`)
}

# If 'precipitation' is equivalent to 'rain', remove 'precipitation'
if (all(data$`precipitation (mm)`  == data$`rain (mm)`)) {
  data <- data %>% select(-`precipitation (mm)`)
}
```


Now in order to proceed with the computation, the `time` variable can be grouped into daily data averaging by the mean. The averagin by the mean will per performed to those values which are "constrained" such as wind degree and so on, the amount of rain will be summed, since it's a quantity not constrained.
```{r}
data <- data %>%
  mutate(time = as.Date(time)) %>%
  group_by(time) %>%
  summarise(across(-`rain (mm)`, mean), `rain (mm)` = sum(`rain (mm)`))
```
The new grouped data:
```{r}
paged_table(head(data))
```
Since the data was reduced and grouped, check again for null values
```{r}
sum(is.na(data))
```

Now that the data is ready the data summary can be printed
```{r}
summary(data)
```
All the variables are numeric, but some of them, such as `wind_direction` has some restriction. `wind_direction` needs to be between 0-360; all the percentage variables, needs to range between 0 and 100. All this checks can be done by looking at the `min` and `max` values of the variables.

Since the `time` variable was grouped, `is_Day` is not any more useful now.

```{r}
data <- data %>%
  select(-is_Day)
``` 

```{r}
paged_table(head(data))
```
## Predictors

The aim of the project will be to predict whereas tomorrow will rain, so a new predictor called `willTomorrowRain` is created. having value `1` if at least one millimeter of rain is recorded in the following day in the variable `rain (mm)`; `0` otherwise

```{r}
data <- data %>%
  mutate(willTomorrowRain = ifelse(lead(`rain (mm)`) > 0, 1, 0))
```
Set the response variable as a factor
```{r}
data$willTomorrowRain <- as.factor(data$willTomorrowRain)
data <- data %>%
  filter(!is.na(willTomorrowRain))
```

```{r}
paged_table(head(data))
```
Plot the response variable to see the distribution
```{r}
data %>%
  ggplot(aes(x = willTomorrowRain)) +
  geom_bar()
```
A 2D plot of the two variables on the PCA can be helpful

```{r}
# Perform PCA on the data
pca_data <- train %>%
  select(-willTomorrowRain) %>%
  prcomp(center = TRUE, scale. = TRUE)

# Extract the first two principal components
pca_data <- as.data.frame(pca_data$x[, 1:2])

# Bind the principal components with the response variable
pca_data <- cbind(pca_data, willTomorrowRain = train$willTomorrowRain)

# Plot the first two principal components
pca_data %>%
  ggplot(aes(x = PC1, y = PC2, color = willTomorrowRain)) +
  geom_point()
```


Now we plot the distribution of the features to get more insights into the distribution of them

```{r}
data %>%
  select(-time, -willTomorrowRain) %>%
  gather(key = "feature", value = "value") %>%
  ggplot(aes(x = value)) +
  geom_density() +
  facet_wrap(~feature, scales = "free")
```

Another way to visualize the data is the use of boxplots.

```{r}
data %>%
  select(-time, -willTomorrowRain) %>%
  gather(key = "feature", value = "value") %>%
  ggplot(aes(x = feature, y = value)) +
  geom_boxplot() +
  coord_flip()
```

By looking at the plot is evident that the variables have different scales and/or are skewed, so the data needs to be normalized.
```{r}
data <- data %>%
  select(-time) %>%
  mutate_if(is.numeric, scale)
```
The procedure create some `NaN` values which will set to `0`
```{r}
data[is.na(data)] <- 0
```

Check for collinearity between predictors
```{r}
data %>%
  select(-willTomorrowRain) %>%
  cor() %>%
  corrplot::corrplot()
```

As expected some of the values are correlated, such as `relative_humidity` and `vapour_pressure_deficit (kPa)`. A scatter plot will gave more insights on how the data is correlated.

```{r}
data %>%
  ggplot(aes(x = relative_humidity, y = `vapour_pressure_deficit (kPa)`)) +
  geom_point()
```

There is a correlation between those two variables, but it's not completley linear

```{r}
data %>%
  ggplot(aes(x = `pressure_msl (hPa)`, y = `surface_pressure (hPa)`)) +
  geom_point()
```

Whereas this two variables are more correlated so only one them can be maintened

```{r}
paged_table(data %>% select(-`pressure_msl (hPa)`))
```

Also is worth checking the cloud related variables
```{r}
data %>%
  ggplot(aes(x = `cloud_cover_low (%)`, y = `cloud_cover_mid (%)`)) +
  geom_point()
```

```{r}
data %>%
  ggplot(aes(x = `cloud_cover_mid (%)`, y = `cloud_cover_high (%)`)) +
  geom_point()
```

```{r}
data %>%
  ggplot(aes(x = `cloud_cover (%)`, y = `cloud_cover_mid (%)`)) +
  geom_point()
```

From this scatter plots there is no clear evidence of a linear correlation between clouds variables.

Plot again the predictors after being normalized
```{r warning = FALSE}
data %>%
  select(-willTomorrowRain) %>%
  gather(key = "feature", value = "value") %>%
  ggplot(aes(x = value)) +
  geom_density() +
  facet_wrap(~feature, scales = "free")
```

```{r}
paged_table(head(data))
```


# Data preparation
Set the `seed` in order to allow reproducibility of the project

```{r}
set.seed(0)
```

Split the data into `train` and `test` set
```{r}
train_index <- sample(1:nrow(data), 0.8 * nrow(data))
train <- data[train_index, ]
test <- data[-train_index, ]
```

## Model
The first model implemented is the random forest model
```{r}
tune_rf_spec <- rand_forest(
  mtry = 13,
  trees = 2000,
  mode = "classification"
) %>%
  set_engine("ranger", importance = "impurity")

# Create a recipe for pre-processing
rain_rf_recipe <- recipe(willTomorrowRain ~ ., data = train) %>%
  step_dummy(all_nominal_predictors()) %>%
  step_zv(all_predictors())

# Create a workflow to combine the model and the recipe
rf_workflow <- workflow() %>%
  add_model(tune_rf_spec) %>%
  add_recipe(rain_rf_recipe)
```


Fit the model to the train

```{r}
rf_fit <- fit(rf_workflow, data = train)
```

Evaluate performances

```{r}
# Evaluate the model's performance on the training set
train_predictions <- rf_fit %>%
  predict(train) %>%
  bind_cols(train)

# Evaluate the model's performance on the test set
test_predictions <- rf_fit %>%
  predict(test) %>%
  bind_cols(test)
```


Calculate metrics
```{r}
# Calculate metrics for training set
train_metrics <- train_predictions %>%
  metrics(truth = willTomorrowRain, estimate = .pred_class)

# Calculate metrics for test set
test_metrics <- test_predictions %>%
  metrics(truth = willTomorrowRain, estimate = .pred_class)
```

```{r}
paged_table(train_metrics)
```
```{r}
paged_table(test_metrics)
```
From this output a little but of overfitting is present since the accuracy on the test set is lower compared to the one on the training set

```{r warning = FALSE}
# Variable importance
rf_fit %>%
  pull_workflow_fit() %>%
  vip(num_features = 13)
```

Can be trivial to say that the most important variable is the rainfall of the previous day, but that variable can also be equal to 0 and combined with `dew_point` leads to a good prediction. Now to be sure, the same task can be performed but without `rain (mm)`.

```{r}
tune_rf_spec <- rand_forest(
  mtry = 12,
  trees = 2000,
  mode = "classification"
) %>%
  set_engine("ranger", importance = "impurity")

# Create a recipe for pre-processing
rain_rf_recipe <- recipe(willTomorrowRain ~ ., data = train) %>%
  step_rm(`rain (mm)`) %>%
  step_dummy(all_nominal_predictors()) %>%
  step_zv(all_predictors())

# Create a workflow to combine the model and the recipe
rf_workflow <- workflow() %>%
  add_model(tune_rf_spec) %>%
  add_recipe(rain_rf_recipe)

rf_fit <- fit(rf_workflow, data = train)

# Evaluate the model's performance on the training set
train_predictions <- rf_fit %>%
  predict(train) %>%
  bind_cols(train)

# Evaluate the model's performance on the test set
test_predictions <- rf_fit %>%
  predict(test) %>%
  bind_cols(test)

# Calculate metrics for training set
train_metrics <- train_predictions %>%
  metrics(truth = willTomorrowRain, estimate = .pred_class)

# Calculate metrics for test set
test_metrics <- test_predictions %>%
  metrics(truth = willTomorrowRain, estimate = .pred_class)
```

```{r}
paged_table(train_metrics)
```

```{r}
paged_table(test_metrics)
```

```{r}
# Variable importance
rf_fit %>%
  pull_workflow_fit() %>%
  vip(num_features = 13)
```

The results are similar to the previous and the most important variable now is `dew_point`.


In order to compare the accuracy, a shallow forecast method is produced. The method will forecast the tomorrows rain only if it rained today
```{r}
train %>%
  mutate(
    willTomorrowRain = as.numeric(as.character(willTomorrowRain)),
    predictedRain = ifelse(lag(willTomorrowRain, default = 0) == 0, 0, 1)
  ) %>%
  summarise(
    accuracy = sum(willTomorrowRain == predictedRain) / n()
  )
```
The result is almost a random guess.


Now a smaller forest can be tried to compare the results since overfitting was experienced. As a rule of thumb for random forest, the number of tree should be around $\sqrt p$ for classification.
```{r}
# Define the random forest model specification
tune_rf_spec <- rand_forest(
  mtry = 13,
  trees = 4,
  mode = "classification"
) %>%
  set_engine("ranger", importance = "impurity")

# Create a workflow to combine the model and the recipe
rf_workflow <- workflow() %>%
  add_model(tune_rf_spec) %>%
  add_recipe(rain_rf_recipe)
```

```{r warning = FALSE}
rf_fit <- fit(rf_workflow, data = train)
```

```{r}
# Evaluate the model's performance on the training set
train_predictions <- rf_fit %>%
  predict(train) %>%
  bind_cols(train)

# Evaluate the model's performance on the test set
test_predictions <- rf_fit %>%
  predict(test) %>%
  bind_cols(test)

# Calculate metrics for training set
train_metrics <- train_predictions %>%
  metrics(truth = willTomorrowRain, estimate = .pred_class)

# Calculate metrics for test set
test_metrics <- test_predictions %>%
  metrics(truth = willTomorrowRain, estimate = .pred_class)
```

```{r}
paged_table(train_metrics)
```


```{r}
paged_table(test_metrics)
```

Variable importance
```{r}
# Variable importance
rf_fit %>%
  pull_workflow_fit() %>%
  vip(num_features = 13)
```

The results are similar to the previous but slightly better.

Now a random search on the space can be performed to find better results. A grid search can also be performed to find the global optimum in the search space, but it can be computationally expensive.

```{r}
# Define the random forest model specification with tuning parameters
tune_rf_spec <- rand_forest(
  mtry = tune(),
  trees = tune(),
  min_n = tune(),
  mode = "classification"
) %>%
  set_engine("ranger", num.threads = 7)

# Create cross-validation folds
data_folds <- vfold_cv(data)

# Create a recipe for pre-processing
# Create a recipe for pre-processing
rain_rf_recipe <- recipe(willTomorrowRain ~ ., data = train) %>%
  step_dummy(all_nominal_predictors()) %>%
  step_zv(all_predictors())

# Create a workflow to combine the model and the recipe
rain_rf_wflow <- workflow() %>%
  add_model(tune_rf_spec) %>%
  add_recipe(rain_rf_recipe)

# Define the metrics to evaluate
metr_res <- metric_set(kap, accuracy)

# Perform random search tuning
rf_reg_tune <- rain_rf_wflow %>%
  tune_grid(
    data_folds,
    grid = grid_random(
      trees(range = c(100, 1000)),
      mtry(range = c(8, 13)),
      min_n(range = c(6, 8)),
      size = 5
    ),
    metrics = metr_res
  )

# Collect and print the metrics
paged_table(rf_reg_tune %>% collect_metrics())

# Select the best configuration based on the "kap" metric
best_f1 <- rf_reg_tune %>% select_best(metric = "kap")

# Finalize the model with the best configuration
final_rf <- finalize_model(tune_rf_spec, best_f1)

# Print the best result configuration
print(best_f1)

# Output the final model
final_rf
```


## Extreme Gradient Boosting
Now another model is implemented, the Extreme Gradient Boosting.

```{r}
# Define the XGBoost model specification with tuning parameters
tune_btree_spec <- boost_tree(
  learn_rate = tune(),
  tree_depth = tune(),
  trees = tune(),
  mode = "classification"
) %>%
  set_engine("xgboost", nthreads = parallel::detectCores())

# Create cross-validation folds
rain_folds <- vfold_cv(train)

# Create a recipe for preprocessing
rain_rf_recipe <- recipe(willTomorrowRain ~ ., data = train) %>%
  step_dummy(all_nominal_predictors()) %>%
  step_zv(all_predictors())

# Create a workflow to combine the model and the recipe
btree_wflow <- workflow() %>%
  add_model(tune_btree_spec) %>%
  add_recipe(rain_rf_recipe)

# Define the metrics to evaluate
metr_res <- metric_set(kap, accuracy)

# Perform random search tuning
btree_reg_tune <- btree_wflow %>%
  tune_grid(
    rain_folds,
    grid = grid_random(
      learn_rate(),
      tree_depth(range = c(2, 8)),
      trees(range = c(5, 20)),
      size = 10
    ),
    metrics = metr_res
  )

# Collect and print the metrics
paged_table(btree_reg_tune %>% collect_metrics())

# Select the best configuration based on the "kap" metric
best_btree_f1 <- btree_reg_tune %>% select_best(metric = "kap")

# Finalize the model with the best configuration
final_btree <- finalize_model(tune_btree_spec, best_btree_f1)

# Print the best result configuration
print(best_btree_f1)

# Output the final model
final_btree
```

Calculate the accuracy

```{r warning = FALSE}
# Define the formula for the model
formula <- willTomorrowRain ~ .

# Fit the model to the training data using the formula
final_btree_fit <- fit(final_btree, formula = formula, data = train)

# Evaluate the model's performance on the training set
train_predictions <- final_btree_fit %>%
  predict(train) %>%
  bind_cols(train)

# Evaluate the model's performance on the test set
test_predictions <- final_btree_fit %>%
  predict(test) %>%
  bind_cols(test)

# Calculate metrics for training set
train_metrics <- train_predictions %>%
  metrics(truth = willTomorrowRain, estimate = .pred_class)

# Calculate metrics for test set
test_metrics <- test_predictions %>%
  metrics(truth = willTomorrowRain, estimate = .pred_class)
```

Print the train metrics
```{r}
paged_table(train_metrics)
```

Print the test metrics
```{r}
paged_table(test_metrics)
```


```{r warning = FALSE}
# Assuming final_btree is the finalized model specification
# Create a new workflow with the finalized model
final_btree_wflow <- workflow() %>%
  add_model(final_btree) %>%
  add_recipe(rain_rf_recipe)

# Fit the workflow to the training data
final_btree_fit <- fit(final_btree_wflow, data = train)

# Plot the variable importance
final_btree_fit %>%
  pull_workflow_fit() %>%
  vip(num_features = 13)
```

The first tree can be plotted to better visualize the splitting performed
```{r}
xgb_model <- final_btree_fit %>%
  pull_workflow_fit() %>%
  .$fit
# Visualize the first tree in the model
xgb.plot.tree(model = xgb_model, trees = 0)
```


## Conclusion

This project evaluated the effectiveness of Random Forest and Extreme Gradient Boosting (XGBoost) in the classification of weather data to predict the likelihood of rain on the following day. The dataset, originally structured as a time series, was preprocessed to be treated as independent observations for modeling purposes.

The results demonstrated that Random Forest and XGBoost obtained similar results in this particular case. Both models highlighted the significance of the amount of rainfall on the current day as the primary predictor of whether it would rain the next day. The presence or absence of rainfall was a critical factor in determining whether the subsequent day would also be classified as rainy. However, one notable limitation of this approach is that rain occurring overnight (for example, during a storm that spans midnight) may result in the following day being classified as rainy, even if precipitation occurred only briefly after midnight. To account for this limitation, the model was tried without that predictor and lead to similar results.

The second most important variable identified by both models was the dew_point, indicating the relevance of the relationship between humidity and temperature in predicting rainfall. This finding suggests that atmospheric moisture, as captured by the dew point, plays a critical role in determining rain conditions for the next day.
















